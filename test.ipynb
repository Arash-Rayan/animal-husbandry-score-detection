{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3effaf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import Blip2Processor , Blip2ForConditionalGeneration\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model_name = 'Salesforce/blip2-opt-2.7b'\n",
    "# processor = Blip2Processor.from_pretrained(model_name)\n",
    "# model = Blip2ForConditionalGeneration.from_pretrained(model_name, device_map= 'auto')\n",
    "# image = test \n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc11516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load model and processor\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\", device_map=\"auto\", torch_dtype=torch.float16)\n",
    "\n",
    "# Load image\n",
    "image = Image.open(\"your_image.jpg\").convert(\"RGB\")\n",
    "\n",
    "# Prepare inputs\n",
    "inputs = processor(images=image, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "\n",
    "# Generate caption\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=50)\n",
    "caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(\"Caption:\", caption)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
